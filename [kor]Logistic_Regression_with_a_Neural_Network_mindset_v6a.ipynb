{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with a Neural Network mindset\n",
    "\n",
    "Logistic Regression을 통해서 고양이인지 여부를 판단하는 분류기(classifier)를 작성하는 과제를 수행합니다. 이를 통해서 신경망과 딥러닝에 대한 이해를 높입니다. \n",
    "\n",
    "**주의:**\n",
    "- for 또는 while과 같은 루프는 성능을 매우 저하시킵니다. 루프는 명시되지 않은 경우 사용을 하지 않도록 하세요. \n",
    "\n",
    "\n",
    "**배울 내용들:**\n",
    "- 학습 알고리즘의 기초들:\n",
    "    - 파라미터의 초기화\n",
    "    - cost function의 계산과 gradient의 계산\n",
    "    - gradient descent를 이용한 최적화 알고리즘\n",
    "- 위의 3가지 기능을 하나의 딥러닝 모델에 적절한 순서로 배치하기.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages ##\n",
    "\n",
    "다음의 파이선 패키지들이 과제를 위해서 필요합니다. import하도록 하세요. \n",
    "- [numpy](www.numpy.org)는 파이선에서 텐서 연산을 할수있도록 합니다. \n",
    "- [h5py](http://www.h5py.org)는 H5라는 형식으로 저장된 데이터를 읽고, 저장하기 위해서 필요합니다. \n",
    "- [matplotlib](http://matplotlib.org)는 다양한 형태의 그래프를 그리는데 유용합니다.\n",
    "- [PIL](http://www.pythonware.com/products/pil/)과 [scipy](https://www.scipy.org/)는 사진을 다루기 위해서 필요합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from lr_utils import load_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Overview of the Problem set ##\n",
    "\n",
    "**Problem Statement**: 주어진 \"data.h5\"데이터셋은 다음을 포함합니다. :\n",
    "- m_train개의 학습 데이터는 \"고양이\" (y=1) 또는 \"고양이-아님\" (y=0)으로 레이블이 되어 있음.\n",
    "- m_test개의 테스트 데이터는 \"고양이\" (y=1) 또는 \"고양이-아님\" (y=0)으로 레이블이 되어 있음.\n",
    "- 각각의 이미지는 (num_px, num_px, 3)의 모양(shape)을 갖는 텐서입니다. 즉, 가로가 num_px, 세로가 num_px의 크기이며, RGB의 3개의 채널을 갖는 이미지입니다.\n",
    "\n",
    "당신은 이미지를 \"고양이\"인지 아닌지를 분류하는 classifier를 작성해야합니다.\n",
    "\n",
    "먼저, 데이터셋에 익숙해지기 위해서, 다음 코드로 데이터셋을 불러옵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 64, 64, 3)\n",
      "(1, 209)\n",
      "(2,)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "# Loading the data (cat/non-cat)\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()\n",
    "\n",
    "print(train_set_x_orig.shape)\n",
    "print(train_set_y.shape)\n",
    "print(classes.shape)\n",
    "print(train_set_x_orig.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋들에 \"_orig\"라는 이름이 붙어있는데, 이것은 우리가 지금의 데이터셋을 전처리(preprocessing)하여 새로운 데이터를 만들려고 하기 때문입니다. \n",
    "전처리가 된 데이터들은 train_set_x, test_set_x같은 이름을 갖도록 할것입니다. \n",
    "\n",
    "train_set_x_orig 와 test_set_x_orig에서 각각의 라인은 하나의 이미지를 나타냅니다. 다음을 통해 하나의 이미지를 확인해보겠습니다. 변수 index의 값을 바꾸어서 다른 이미지도 확인해보세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 0, it's a 'non-cat' picture.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 9\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(train_set_y[0, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 프로그램에서 가장 흔한 에러는 matrix와 vector의 차원(dimension)이 맞지 않아서 발생합니다. \n",
    "텐서의 차원에 대해서 주의를 항상 써야합니다. \n",
    "**Exercise:** 다음 값들을 찾아보세요:\n",
    "- m_train (training examples의 갯수)\n",
    "- m_test (test examples의 갯수)\n",
    "- num_px (학습 이미지의 height 와 width)\n",
    "\n",
    "`train_set_x_orig`은 (m_train, num_px, num_px, 3)의 shape를 갖는 numpy 어레이(텐서)입니다. \n",
    "예를 들어, m_train은 'train_set_x_orig.shape[0]'로 접근할수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 209\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'm_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m### END CODE HERE ###\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of training examples: m_train = \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(m_train))\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of testing examples: m_test = \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mm_test\u001b[49m))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeight/Width of each image: num_px = \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(num_px))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEach image is of size: (\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(num_px) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(num_px) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, 3)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm_test' is not defined"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (≈ 3 lines of code)\n",
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "num_px = train_set_x_orig.shape[1]\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다음 같은 값들이 출력되어야 합니다.**: \n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "    <td>m_train </td>\n",
    "    <td> 209 </td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m_test</td>\n",
    "    <td> 50 </td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>num_px</td>\n",
    "    <td> 64 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 모양(shape)이 (num_px, num_px, 3)인 numpy-array 이미지를  (num_px $*$ num_px $*$ 3, 1)의 모양을 갖도록 변형하여 사용합니다. \n",
    " 지금부터는 training과 test 데이터셋의 이미지는 평탄화되어 하나의 이미지가 하나의 컬럼(column)으로 표현됩니다. \n",
    " 따라서, 학습 데이터셋은 m_train개의 컬럼을 갖게 됩니다. \n",
    "\n",
    "**Exercise:** \n",
    "training과 test 데이터셋의 모양이 (num\\_px $*$ num\\_px $*$ 3, 1)이 되도록 만드세요. \n",
    "\n",
    "힌트로서, (a, b, c, d)의 모양을 갖는 텐서 X를 평탄(flatten)화 시켜서 (b$*$c$*$d, a)로 만들기 위해서는 다음의 코드를 사용합니다:\n",
    "```python\n",
    "X_flatten = X.reshape((X.shape[0], -1)).T      # X.T is the transpose of X\n",
    "```\n",
    "또는,\n",
    "```python\n",
    "X_flatten = np.reshape(X, (X.shape[0], -1)).T\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the training and test examples\n",
    "\n",
    "### START CODE HERE ### (≈ 2 lines of code)\n",
    "\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
    "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다음 같은 값들이 출력되어야 합니다.**: \n",
    "\n",
    "<table style=\"width:35%\">\n",
    "  <tr>\n",
    "    <td>train_set_x_flatten shape</td>\n",
    "    <td> (12288, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>train_set_y shape</td>\n",
    "    <td>(1, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>test_set_x_flatten shape</td>\n",
    "    <td>(12288, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>test_set_y shape</td>\n",
    "    <td>(1, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td>sanity check after reshaping</td>\n",
    "  <td>[17 31 56 22 33]</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컬러 이미지의 한 픽셀은 red, green, blue의 3개 채널로 구성됩니다. 따라서, 한 픽셀은 실제 0-255사이의 값을 갖는 3개의 숫자 벡터입니다. \n",
    "\n",
    "머신러닝에서 일반적인 데이터의 전처리는 평균(mean)을 빼고, 표준편차(standard deviation)로 나누어서 표준화 시키는 것입니다. \n",
    "그러나, 이미지 데이터에서는 각 픽셀값들을 255로 나누어서 부동소수점으로 만드는 것으로 충분한 경우가 많습니다. \n",
    "\n",
    "데이터셋을 표준화시켜 봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**기억할것들:**\n",
    "\n",
    "데이터셋을 위한 일반적인 표준화 방법은:\n",
    "- 다룰 데이터셋의 모양(shape)을 파악합니다. (m_train, m_test, num_px, ...)\n",
    "- 각각의 example들이 (num_px \\* num_px \\* 3, 1) 모양을 갖는 벡터로 만듭니다. \n",
    "- 데이터를 \"표준화\"시킵니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3 - General Architecture of the learning algorithm ##\n",
    "\n",
    "이미지가 고양이인지 아닌지를 분류할 알고리즘을 만들 차례입니다. \n",
    "\n",
    "다음 그림에서 보듯이 Logistic Regression은 아주 단순한 neural network라고 할수 있습니다. \n",
    "\n",
    "<img src=\"images/LogReg_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "\n",
    "**Cost값을 구하는 알고리즘의 수학적인 표현입니다**:\n",
    "\n",
    "하나의 이미지 example $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "cost는 모든 training examples들을 loss들을 더해서 평균을 구합니다:\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$\n",
    "\n",
    "**Key steps**:\n",
    "다음 연습에서는 다음과 같은 과정을 완성해야합니다.:\n",
    "- 모델의 파라미터 초기화\n",
    "- cost값을 최소화 파라미터 값을 학습하기\n",
    "- 학습된 파라미터를 이용하여 test데이터셋에 대해서 예측(prediction)하기\n",
    "- 결과 분석과 결론"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - 알고리즘의 각 부분들 만들기 ## \n",
    "\n",
    "Neural network를 만드는 주요 과정입니다:\n",
    "1. 모델의 구조를 정의합니다 (예: 입력 피쳐의 갯수 등을 결정.)\n",
    "2. 모델의 파라미터를 초기화 합니다. \n",
    "3. 반복하기:\n",
    "    - loss 계산하기 (forward propagation)\n",
    "    - gradient 계산하기 (backward propagation)\n",
    "    - 파라미터 값 갱신하기 (gradient descent)\n",
    "\n",
    "대부분 1-3을 각각 별도록 구현하여, model()함수에 통합하게 됩니다. \n",
    "\n",
    "### 4.1 - 필요한 도움 함수 (helper functions) 구현\n",
    "\n",
    "**Exercise**: `sigmod()`함수는 위의 그림에서 보이듯이 neural network의 마지막에서 사용됩니다. $sigmoid(z) = \\frac{1}{1 + e^{-z}}$로 정의됩니다.\n",
    "np.exp()를 사용하여 sigmod()함수를 구현하세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다음 같은 값들이 출력되어야 합니다.**: \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>sigmoid([0, 2])</td>\n",
    "    <td> [ 0.5         0.88079708]</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - 파라미터 초기화\n",
    "\n",
    "**Exercise:** 아래에 파라미터를 초기화하세요. w는 0값들의 벡터로 초기화 합니다. numpy에서는 np.zeros()가 텐서를 0으로 만드는데 사용됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 2 line of code)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다음 같은 값들이 출력되어야 합니다.**: \n",
    "\n",
    "<table style=\"width:15%\">\n",
    "    <tr>\n",
    "        <td>  w  </td>\n",
    "        <td> [[ 0.]\n",
    " [ 0.]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  b   </td>\n",
    "        <td> 0 </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "이미지 입력에 대해서, w는 (num_px $\\times$ num_px $\\times$ 3, 1)의 모양(shape)을 갖습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Forward and Backward propagation\n",
    "\n",
    "파라미터가 초기화되었으니, 'forward'와 'backward' propagation을 통해서 파라미터 값들을 학습하는 단계입니다.\n",
    "\n",
    "**Exercise:** cost 값과 gradient를 구하는 `propagate()` 함수를 구현합니다. \n",
    "\n",
    "**Hints**:\n",
    "\n",
    "Forward Propagation:\n",
    "- 입력 X를 받는다.\n",
    "- $A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$를 계산한다.\n",
    "- $J = -\\frac{1}{m}\\sum_{i=1}^{m} \\{y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})\\}$를 계산한다.\n",
    "\n",
    "Backward Propagation:\n",
    "- 다음의 2개 식을 사용합니다:\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \n",
    "    Tips:\n",
    "    - Write your code step by step for the propagation. np.log(), np.dot()\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다음 같은 값들이 출력되어야 합니다.**: \n",
    "\n",
    "<table style=\"width:50%\">\n",
    "    <tr>\n",
    "        <td>   dw   </td>\n",
    "      <td> [[ 0.99845601]\n",
    "     [ 2.39507239]]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>   db   </td>\n",
    "        <td> 0.00145557813678 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>   cost  </td>\n",
    "        <td> 5.801545319394553 </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - Optimization (최적화)\n",
    "- 지금까지 당신은 파라미터를 초기화하였고, \n",
    "- cost 함수값과 gradient를 계산하였습니다. \n",
    "- 이제는, gradient descent를 이용하여 파라미터를 갱신할 차례입니다.\n",
    "\n",
    "**Exercise:** 최적화 함수인 optimize()를 구현합니다. 여기에서는 cost함수인 $J$를 최소화하여 $w$와 $b$를 학습하는 것입니다. 파라미터가 $\\theta$라면, $ \\theta = \\theta - \\alpha \\text{ } d\\theta$와 같이 파라미터 값을 갱신합니다. 여기서 $\\alpha$는 learning rate입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: optimize\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Cost and gradient calculation (≈ 1-4 lines of code)\n",
    "        ### START CODE HERE ### \n",
    "\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule (≈ 2 lines of code)\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 100 training iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations= 1000, learning_rate = 0.009, print_cost = False)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(costs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다음 같은 값들이 출력되어야 합니다.**: \n",
    "<table style=\"width:40%\">\n",
    "    <tr>\n",
    "       <td> w </td>\n",
    "       <td>[[ 0.19033591] [ 0.12259159]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> b </td>\n",
    "       <td> 1.92535983008 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> dw </td>\n",
    "       <td> [[ 0.67752042]\n",
    " [ 1.41625495]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> db </td>\n",
    "       <td> 0.219194504541 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** 앞서의 함수는 학습된 w와 b를 출력합니다. 이제, 학습된 w와 b를 이용하여 데이터셋 X에 대해서 값을 예측해봅니다. `predict()`함수를 구현하십시오. \n",
    "이 함수는 2가지 단계를 수행합니다. \n",
    "\n",
    "1. 예측값인 $\\hat{Y} = A = \\sigma(w^T X + b)$를 계산합니다.\n",
    "\n",
    "2. A의 값을 0 (activation <= 0.5인 경우) 또는 1 (activation > 0.5인 경우)로 바꿉니다. 예측된 이 값들을 `Y_prediction`에 저장합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "                                  # Dimentions = (1, m)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    Y_prediction[A > 0.5] = 1\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[0.1124579],[0.23106775]])\n",
    "b = -0.3\n",
    "X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\n",
    "print (\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다음 같은 값들이 출력되어야 합니다.**: \n",
    "\n",
    "<table style=\"width:30%\">\n",
    "    <tr>\n",
    "         <td>\n",
    "             predictions\n",
    "         </td>\n",
    "          <td>\n",
    "            [[ 1.  1.  0.]]\n",
    "         </td>  \n",
    "   </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What to remember:**\n",
    "지금까지 다음의 함수들을 구현하였습니다:\n",
    "- (W, b)를 초기화\n",
    "- 파라미터 (w, b)를 학습하기 위해서 loss를 반복적으로 감소시킴:\n",
    "    - cost와 gradient를 계산\n",
    "    - gradient descent를 통해 파라미터 갱신\n",
    "-  학습된 (w, b)를 이용하여 주어진 이미지 입력에 대해서 예측값 생성\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 -구현된 모든 기능들을 하나의 모델에 통합합니다. ##\n",
    "\n",
    "**Exercise:** `model()`함수를 구현합니다. 다음의 표기법이 사용됩니다:\n",
    "Implement the model function. Use the following notation:\n",
    "- Y_prediction_test는 test데이터셋에 대한 예측값입니다.\n",
    "- Y_prediction_train는 train데이터셋에 대한 예측값입니다.\n",
    "- w, cost, grads는 optimize()함수에서의 출력값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # initialize parameters with zeros (≈ 1 line of code)\n",
    "\n",
    "\n",
    "    # Gradient descent (≈ 1 line of code)\n",
    "\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    w = params[\"w\"]\n",
    "    b = params[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples (≈ 2 lines of code)\n",
    "\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 학습시키기 위해서 다음의 코드를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다음 같은 값들이 출력되어야 합니다.**: \n",
    "<table style=\"width:40%\"> \n",
    "    <tr>\n",
    "        <td> Cost after iteration 0  </td> \n",
    "        <td> 0.693147 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Train Accuracy  </td> \n",
    "        <td> 99.04306220095694 % </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Test Accuracy </td> \n",
    "        <td> 70.0 % </td>\n",
    "    </tr>\n",
    "</table> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: training 예측 정확도는 100%에 가깝습니다. 이건 모델이 학습데이터를 충분히 학습할만한 용량을 가지고 있다는 것을 말해줍니다. 그러나, test 예측 정확도는 약 70%입니다. Logistic regression과 같은 매우 단순한 모델에서 이정도의 정확도는 그다지 나쁜것은 아닙니다. 앞으로, 여러가지 방법들을 사용하여 정확도를 계속 높여 나갈 것입니다. \n",
    "\n",
    "지금처럼 training 정확도와 test정확도가 차이가 많이 나는 것을 과적합(overfitting)되었다고 합니다. 앞으로 배울 정규화(regularization)와 같은 방법을 사용하여 과적합을 줄일수 있습니다. \n",
    "\n",
    "아래에서 `index`값을 바꾸어서 test데이터에 대해서 예측값들이 어떤지를 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a picture that was wrongly classified.\n",
    "index = 25\n",
    "print(d[\"Y_prediction_test\"][0,index])\n",
    "plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))\n",
    "print (\"y = \" + str(test_set_y[0,index]) + \", you predicted that it is a \\\"\" + classes[int(d[\"Y_prediction_test\"][0,index])].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습동안 cost함수 값이 어떻게 변하는지를 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "cost값이 감소하는 것을 볼수 있습니다. 이것은 파라미터 학습이 이루어지고 있음을 보입니다. iteratgions를 늘려서 학습시간을 늘릴수도 있습니다. 학습시간을 늘리면, traing예측정확도는 높아지지만, test 예측 정확도는 오히려 감소하는 것을 발견하게 될것입니다. 이것을 과적합(overfitting)이 발생하고 있다고 합니다. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Further analysis (optional/ungraded exercise) ##\n",
    "\n",
    "축하합니다. 당신의 첫번째 이미지 분류 모델을 완성하였습니다. \n",
    "이제 learing rate인 $\\alpha$를 달리할때 어떤 영향이 있는지 살펴봅니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choice of learning rate ####\n",
    "\n",
    "**Reminder**:\n",
    "Gradient descent가 제대로 동작하기 위해서는 learning rate를 잘 설정해야합니다. Learning rate $\\alpha$는 파라미터가 얼마나 빨리 갱신될지를 결정합니다. \n",
    "만약에 learing rate가 너무 크면 \"overshoot\"가 발생합니다. 반대로, learing rate가 너무 작으면 학습속도가 너무 느려지게 됩니다. \n",
    "\n",
    "우리 모델에서 learing rate값을 달리하면서 cost가 어떻게 감소하는지 비교해봅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "models = {}\n",
    "for i in learning_rates:\n",
    "    print (\"learning rate is: \" + str(i))\n",
    "    models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 1500, learning_rate = i, print_cost = False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
    "\n",
    "for i in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(i)][\"costs\"]), label= str(models[str(i)][\"learning_rate\"]))\n",
    "\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (hundreds)')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: \n",
    "- learing rate가 바뀌면, cost값들도 바뀌고 예측결과도 바뀐다. \n",
    "- learing rate가 너무 크면 (예: 0.01), cost값이 위 아래로 요동치게 됩니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "myyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 213.4,
   "position": {
    "height": "235.4px",
    "left": "1160px",
    "right": "20px",
    "top": "126px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
